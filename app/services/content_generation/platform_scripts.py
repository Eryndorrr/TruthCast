"""
å¤šå¹³å°è¯æœ¯ç”Ÿæˆæ¨¡å—

æ ¹æ®æ¾„æ¸…ç¨¿å’Œæ£€æµ‹ç»“æœï¼Œç”Ÿæˆé€‚é…ä¸åŒå¹³å°çš„å‘å¸ƒè¯æœ¯ã€‚
æ”¯æŒ 9 ä¸ªå¹³å°ï¼š
- å¾®åšã€å¾®ä¿¡å…¬ä¼—å·ã€çŸ­è§†é¢‘å£æ’­(é€šç”¨)
- æ–°é—»é€šç¨¿ã€å®˜æ–¹å£°æ˜
- å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ã€Bç«™
"""

import json
import os
from datetime import datetime, timezone
from typing import Any

import httpx

from app.core.logger import get_logger
from app.schemas.detect import (
    ClarificationContent,
    PlatformScript,
    Platform,
    ReportResponse,
    SimulateResponse,
)
from app.services.json_utils import safe_json_loads, serialize_for_json

logger = get_logger(__name__)

# é…ç½®
CONTENT_LLM_ENABLED = os.getenv("TRUTHCAST_CONTENT_LLM_ENABLED", "false").lower() == "true"
CONTENT_LLM_MODEL = os.getenv("TRUTHCAST_CONTENT_LLM_MODEL", "")
CONTENT_LLM_BASE_URL = os.getenv("TRUTHCAST_CONTENT_LLM_BASE_URL", os.getenv("TRUTHCAST_LLM_BASE_URL", "https://api.openai.com/v1"))
CONTENT_LLM_API_KEY = os.getenv("TRUTHCAST_CONTENT_LLM_API_KEY", os.getenv("TRUTHCAST_LLM_API_KEY", ""))
CONTENT_TIMEOUT_SEC = int(os.getenv("TRUTHCAST_CONTENT_TIMEOUT_SEC", "45"))
DEBUG_CONTENT = os.getenv("TRUTHCAST_DEBUG_CONTENT", "true").lower() == "true"

# å¹³å°å­—æ•°é™åˆ¶
PLATFORM_WEIBO_MAX = int(os.getenv("TRUTHCAST_PLATFORM_WEIBO_MAX", "280"))
PLATFORM_WECHAT_MAX = int(os.getenv("TRUTHCAST_PLATFORM_WECHAT_MAX", "1000"))
PLATFORM_XIAOHONGSHU_MAX = int(os.getenv("TRUTHCAST_PLATFORM_XIAOHONGSHU_MAX", "500"))
PLATFORM_DOUYIN_MAX_SEC = int(os.getenv("TRUTHCAST_PLATFORM_DOUYIN_MAX_SEC", "60"))
PLATFORM_KUAISHOU_MAX_SEC = int(os.getenv("TRUTHCAST_PLATFORM_KUAISHOU_MAX_SEC", "90"))
PLATFORM_BILIBILI_MAX_SEC = int(os.getenv("TRUTHCAST_PLATFORM_BILIBILI_MAX_SEC", "180"))


# å¹³å°é…ç½®
PLATFORM_CONFIGS = {
    Platform.WEIBO: {
        "name": "å¾®åš",
        "max_length": PLATFORM_WEIBO_MAX,
        "features": ["è¯é¢˜æ ‡ç­¾", "è½¬å‘å‹å¥½", "å£è¯­åŒ–"],
        "tips": ["æœ€ä½³å‘å¸ƒæ—¶é—´ï¼šå·¥ä½œæ—¥æ—©8-9ç‚¹æˆ–æ™š8-10ç‚¹", "å»ºè®®é…å›¾1-3å¼ ", "ç§¯æå›å¤è¯„è®ºå¢åŠ äº’åŠ¨"],
    },
    Platform.WECHAT: {
        "name": "å¾®ä¿¡å…¬ä¼—å·",
        "max_length": PLATFORM_WECHAT_MAX,
        "features": ["æ’ç‰ˆå‹å¥½", "å¯æ’å…¥å¼•ç”¨", "å›¾æ–‡å¹¶èŒ‚"],
        "tips": ["æ ‡é¢˜å»ºè®®ä½¿ç”¨ç–‘é—®å¥æˆ–æ•°å­—", "æ­£æ–‡åˆ†æ®µæ¸…æ™°", "é…å›¾å»ºè®®3-5å¼ "],
    },
    Platform.SHORT_VIDEO: {
        "name": "çŸ­è§†é¢‘å£æ’­",
        "max_length": 90,  # ç§’
        "features": ["å¼€å¤´å¸å¼•", "æ ¸å¿ƒä¿¡æ¯", "ç»“å°¾äº’åŠ¨"],
        "tips": ["å¼€å¤´3ç§’æŠ“çœ¼çƒ", "å­—å¹•æ¸…æ™°æ˜“è¯»", "BGMé€‰æ‹©åˆé€‚"],
    },
    Platform.NEWS: {
        "name": "æ–°é—»é€šç¨¿",
        "max_length": 800,
        "features": ["å€’é‡‘å­—å¡”ç»“æ„", "æ­£å¼å®¢è§‚", "å¯å¼•ç”¨æƒå¨"],
        "tips": ["æ ‡é¢˜ç®€æ´æœ‰åŠ›", "å¯¼è¯­åŒ…å«æ ¸å¿ƒä¿¡æ¯", "å¯è”ç³»æƒå¨åª’ä½“"],
    },
    Platform.OFFICIAL: {
        "name": "å®˜æ–¹å£°æ˜",
        "max_length": 600,
        "features": ["æ­£å¼ä¸¥è°¨", "æ ‡é¢˜æ­£æ–‡è½æ¬¾", "æ³•å¾‹åˆè§„"],
        "tips": ["éœ€ç»æ³•åŠ¡å®¡æ ¸", "è½æ¬¾éœ€ç›–ç« ", "ä¿ç•™ç­¾å‘è®°å½•"],
    },
    Platform.XIAOHONGSHU: {
        "name": "å°çº¢ä¹¦",
        "max_length": PLATFORM_XIAOHONGSHU_MAX,
        "features": ["æ ‡é¢˜å¸å¼•", "emojié€‚å½“", "ç§è‰é£/åˆ†äº«é£"],
        "tips": ["æ ‡é¢˜å¯ç”¨ç–‘é—®å¥æˆ–æ•°å­—å¼€å¤´", "é…å›¾å»ºè®®ç²¾ç¾å°é¢", "æ ‡ç­¾3-5ä¸ª"],
    },
    Platform.DOUYIN: {
        "name": "æŠ–éŸ³",
        "max_length": PLATFORM_DOUYIN_MAX_SEC,
        "features": ["å¼€å¤´3ç§’æŠ“çœ¼çƒ", "å¿«èŠ‚å¥", "æƒ…ç»ªé¥±æ»¡"],
        "tips": ["å¼€å¤´å‰3ç§’æœ€é‡è¦", "BGMé€‰æ‹©çƒ­é—¨éŸ³ä¹", "å­—å¹•å¤§ä¸”æ¸…æ™°"],
    },
    Platform.KUAISHOU: {
        "name": "å¿«æ‰‹",
        "max_length": PLATFORM_KUAISHOU_MAX_SEC,
        "features": ["æ¥åœ°æ°”", "äº²åˆ‡", "äº’åŠ¨å¼•å¯¼å¼º"],
        "tips": ["å¼€å¤´å¯ç”¨æé—®å¸å¼•", "ç»“å°¾å¼•å¯¼è¯„è®º", "ç”»é¢è‡ªç„¶çœŸå®"],
    },
    Platform.BILIBILI: {
        "name": "Bç«™",
        "max_length": PLATFORM_BILIBILI_MAX_SEC,
        "features": ["ä¸“ä¸šæ·±åº¦", "å¯å¼•ç”¨æ•°æ®", "2-3åˆ†é’Ÿ"],
        "tips": ["å¼€å¤´è®¾ç½®æ‚¬å¿µ", "å¯å¼•ç”¨æ•°æ®æ¥æº", "å¼¹å¹•äº’åŠ¨ç‚¹è®¾è®¡"],
    },
}


def _get_platform_requirements(platforms: list[Platform]) -> str:
    """è·å–å¹³å°è¦æ±‚æè¿°"""
    lines = []
    for i, p in enumerate(platforms, 1):
        config = PLATFORM_CONFIGS.get(p, {})
        lines.append(f"{i}. {config.get('name', p.value)} ({p.value}):")
        if "max_length" in config:
            if p in [Platform.DOUYIN, Platform.KUAISHOU, Platform.BILIBILI, Platform.SHORT_VIDEO]:
                lines.append(f"   - æ—¶é•¿: {config['max_length']}ç§’ä»¥å†…")
            else:
                lines.append(f"   - å­—æ•°: {config['max_length']}å­—ä»¥å†…")
        if config.get("features"):
            lines.append(f"   - ç‰¹ç‚¹: {', '.join(config['features'])}")
        if config.get("tips"):
            lines.append(f"   - å‘å¸ƒå»ºè®®: {config['tips'][0]}")
    return "\n".join(lines)


def _record_trace(stage: str, payload: dict[str, Any]) -> None:
    """è®°å½• debug trace"""
    if not DEBUG_CONTENT:
        return
    
    try:
        current_file = os.path.abspath(__file__)
        services_dir = os.path.dirname(current_file)
        content_dir = os.path.dirname(services_dir)
        app_dir = os.path.dirname(content_dir)
        project_root = os.path.dirname(app_dir)
        
        debug_dir = os.path.join(project_root, "debug")
        os.makedirs(debug_dir, exist_ok=True)
        trace_file = os.path.join(debug_dir, "content_trace.jsonl")
        
        entry = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "module": "platform_scripts",
            "stage": stage,
            "payload": serialize_for_json(payload),
        }
        with open(trace_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    except Exception as exc:
        logger.error("å†™å…¥ content trace å¤±è´¥: %s", exc)


async def _call_llm(prompt: str) -> dict | None:
    """è°ƒç”¨ LLM ç”Ÿæˆå¹³å°è¯æœ¯"""
    if not CONTENT_LLM_ENABLED or not CONTENT_LLM_API_KEY:
        logger.info("[PlatformScripts] LLM not enabled or no API key")
        return None
    
    headers = {
        "Authorization": f"Bearer {CONTENT_LLM_API_KEY}",
        "Content-Type": "application/json",
    }
    
    system_prompt = "ä½ æ˜¯æ–°åª’ä½“è¿è¥ä¸“å®¶ï¼Œæ“…é•¿é’ˆå¯¹ä¸åŒå¹³å°ç”Ÿæˆé€‚é…çš„å‘å¸ƒè¯æœ¯ã€‚è¾“å‡ºå¿…é¡»ä¸ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚"
    user_prompt = prompt

    payload = {
        "model": CONTENT_LLM_MODEL or "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "temperature": 0.7,
        "max_tokens": 8000,
    }
    
    _record_trace(
        "llm_request",
        {
            "base_url": CONTENT_LLM_BASE_URL,
            "model": payload.get("model"),
            "temperature": payload.get("temperature"),
            "max_tokens": payload.get("max_tokens"),
            "system_prompt": system_prompt,
            "user_prompt": user_prompt,
        },
    )
    
    try:
        async with httpx.AsyncClient(timeout=CONTENT_TIMEOUT_SEC) as client:
            response = await client.post(
                f"{CONTENT_LLM_BASE_URL}/chat/completions",
                headers=headers,
                json=payload,
            )
            response.raise_for_status()
            data = response.json()
            content = data["choices"][0]["message"]["content"]
            result = safe_json_loads(content)
            _record_trace(
                "llm_response",
                {
                    "raw_content": content,
                    "result": result,
                },
            )
            return result
    except Exception as exc:
        logger.error("[PlatformScripts] LLM è°ƒç”¨å¤±è´¥: %s", exc)
        _record_trace("llm_error", {"error": str(exc)})
        return None


def _fallback_platform_script(
    platform: Platform,
    clarification: ClarificationContent,
    report: ReportResponse,
) -> PlatformScript:
    """è§„åˆ™å…œåº•ç”Ÿæˆå¹³å°è¯æœ¯"""
    config = PLATFORM_CONFIGS.get(platform, {})
    
    if platform == Platform.WEIBO:
        content = clarification.short[:PLATFORM_WEIBO_MAX]
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            hashtags=["#çœŸç›¸æ¥äº†", "#è¾Ÿè°£"],
            estimated_read_time="30ç§’",
        )
    
    elif platform == Platform.WECHAT:
        content = clarification.long[:PLATFORM_WECHAT_MAX]
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time="2åˆ†é’Ÿ",
        )
    
    elif platform == Platform.SHORT_VIDEO:
        content = f"ã€è¾Ÿè°£æé†’ã€‘{clarification.short}\n\n{clarification.medium}"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time="60ç§’",
        )
    
    elif platform == Platform.NEWS:
        content = f"ã€æ–°é—»é€šç¨¿ã€‘\n\n{clarification.long}"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time="3åˆ†é’Ÿ",
        )
    
    elif platform == Platform.OFFICIAL:
        content = f"ã€å®˜æ–¹å£°æ˜ã€‘\n\n{clarification.long}\n\nç‰¹æ­¤å£°æ˜ã€‚"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time="2åˆ†é’Ÿ",
        )
    
    elif platform == Platform.XIAOHONGSHU:
        content = f"ğŸ” çœŸç›¸æ¥äº†ï¼\n\n{clarification.medium[:PLATFORM_XIAOHONGSHU_MAX]}\n\n#çœŸç›¸ #è¾Ÿè°£"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time="1åˆ†é’Ÿ",
        )
    
    elif platform == Platform.DOUYIN:
        content = f"ã€å¼€å¤´ã€‘è¿™ä¸ªæ¶ˆæ¯æ˜¯çœŸçš„å—ï¼Ÿ\nã€æ­£æ–‡ã€‘{clarification.short}\nã€ç»“å°¾ã€‘å…³æ³¨å®˜æ–¹ä¿¡æ¯ï¼Œä¸ä¿¡è°£ä¸ä¼ è°£ï¼"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time=f"{PLATFORM_DOUYIN_MAX_SEC}ç§’",
        )
    
    elif platform == Platform.KUAISHOU:
        content = f"ã€å¼€å¤´ã€‘æœ‰äººé—®ä½ è¿™ä¸ªé—®é¢˜æ€ä¹ˆå›ï¼Ÿ\nã€æ­£æ–‡ã€‘{clarification.short}\nã€ç»“å°¾ã€‘è¯„è®ºåŒºå‘Šè¯‰æˆ‘ä½ æ€ä¹ˆçœ‹ï¼Ÿ"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time=f"{PLATFORM_KUAISHOU_MAX_SEC}ç§’",
        )
    
    elif platform == Platform.BILIBILI:
        content = f"ã€å¼€å¤´ã€‘ä»Šå¤©æˆ‘ä»¬æ¥èŠèŠè¿™ä»¶äº‹...\n\n{clarification.long}\n\nã€ç»“å°¾ã€‘ä½ æ€ä¹ˆçœ‹ï¼Ÿæ¬¢è¿å¼¹å¹•è®¨è®ºï¼"
        return PlatformScript(
            platform=platform,
            content=content,
            tips=config.get("tips", []),
            estimated_read_time=f"{PLATFORM_BILIBILI_MAX_SEC}ç§’",
        )
    
    else:
        return PlatformScript(
            platform=platform,
            content=clarification.medium,
            tips=[],
            estimated_read_time="1åˆ†é’Ÿ",
        )


async def generate_platform_scripts(
    clarification: ClarificationContent,
    report: ReportResponse,
    simulation: SimulateResponse | None,
    platforms: list[Platform],
) -> list[PlatformScript]:
    """
    ç”Ÿæˆå¤šå¹³å°è¯æœ¯
    
    Args:
        clarification: æ¾„æ¸…ç¨¿
        report: æ£€æµ‹æŠ¥å‘Š
        simulation: èˆ†æƒ…é¢„æ¼”ç»“æœ
        platforms: ç›®æ ‡å¹³å°åˆ—è¡¨
        
    Returns:
        list[PlatformScript]: å¹³å°è¯æœ¯åˆ—è¡¨
    """
    logger.info("[PlatformScripts] å¼€å§‹ç”Ÿæˆå¤šå¹³å°è¯æœ¯, å¹³å°æ•°=%d", len(platforms))
    
    platform_requirements = _get_platform_requirements(platforms)
    
    prompt = f"""ä½ æ˜¯æ–°åª’ä½“è¿è¥ä¸“å®¶ï¼Œéœ€è¦é’ˆå¯¹ä»¥ä¸‹æ¾„æ¸…ç¨¿ç”Ÿæˆå¤šå¹³å°é€‚é…è¯æœ¯ã€‚

ã€æ¾„æ¸…ç¨¿åŸºç¡€å†…å®¹ã€‘
çŸ­ç‰ˆï¼ˆçº¦100å­—ï¼‰ï¼š
{clarification.short}

ä¸­ç‰ˆï¼ˆçº¦300å­—ï¼‰ï¼š
{clarification.medium}

é•¿ç‰ˆï¼ˆçº¦600å­—ï¼‰ï¼š
{clarification.long}

ã€é£é™©ä¿¡æ¯ã€‘
- é£é™©ç­‰çº§: {report.risk_level}
- åœºæ™¯: {report.detected_scenario}

ã€ç›®æ ‡å¹³å°ã€‘
{platform_requirements}

ã€è¾“å‡ºè¦æ±‚ã€‘
ä¸ºæ¯ä¸ªå¹³å°ç”Ÿæˆé€‚é…è¯æœ¯ï¼Œè¾“å‡º JSON æ ¼å¼ï¼š
{{
  "scripts": [
    {{
      "platform": "weibo",
      "content": "å¾®åšæ­£æ–‡...",
      "tips": ["å‘å¸ƒå»ºè®®1", "å‘å¸ƒå»ºè®®2"],
      "hashtags": ["#è¯é¢˜1", "#è¯é¢˜2"]
    }},
    {{
      "platform": "xiaohongshu",
      "content": "å°çº¢ä¹¦æ­£æ–‡...",
      "tips": ["å‘å¸ƒå»ºè®®1"],
      "hashtags": null
    }},
    {{
      "platform": "douyin",
      "content": "æŠ–éŸ³å£æ’­è„šæœ¬...",
      "tips": ["BGMå»ºè®®", "å­—å¹•å»ºè®®"],
      "hashtags": null
    }}
  ]
}}

æ³¨æ„ï¼š
1. å¾®åšå¿…é¡»åŒ…å« hashtags å­—æ®µï¼ˆ2-3ä¸ªè¯é¢˜æ ‡ç­¾ï¼‰
2. è§†é¢‘å¹³å°ï¼ˆæŠ–éŸ³/å¿«æ‰‹/Bç«™/çŸ­è§†é¢‘ï¼‰çš„ content åº”è¯¥æ˜¯å£æ’­è„šæœ¬æ ¼å¼
3. tips å­—æ®µç»™å‡ºå…·ä½“çš„å‘å¸ƒå»ºè®®
"""
    
    # å°è¯• LLM ç”Ÿæˆ
    result = await _call_llm(prompt)
    
    if result and "scripts" in result:
        scripts = []
        platform_map = {p.value: p for p in platforms}
        
        for item in result["scripts"]:
            platform_str = item.get("platform", "")
            platform = platform_map.get(platform_str)
            if platform:
                scripts.append(PlatformScript(
                    platform=platform,
                    content=item.get("content", ""),
                    tips=item.get("tips", []),
                    hashtags=item.get("hashtags"),
                    estimated_read_time=None,
                ))
        
        # è¡¥å……ç¼ºå¤±çš„å¹³å°
        existing_platforms = {s.platform for s in scripts}
        for p in platforms:
            if p not in existing_platforms:
                scripts.append(_fallback_platform_script(p, clarification, report))
        
        if scripts:
            return scripts
    
    # å›é€€åˆ°è§„åˆ™ç”Ÿæˆ
    logger.info("[PlatformScripts] ä½¿ç”¨è§„åˆ™å…œåº•ç”Ÿæˆ")
    return [_fallback_platform_script(p, clarification, report) for p in platforms]
